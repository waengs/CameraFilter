{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class CameraApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        \n",
    "        # 0 is main camera\n",
    "        self.video_source = 0  \n",
    "        self.vid = cv2.VideoCapture(self.video_source) # capture vid using cv2\n",
    "        \n",
    "        # make canvas using tk, showcase live cam\n",
    "        self.canvas = tk.Canvas(window, width=self.vid.get(cv2.CAP_PROP_FRAME_WIDTH), height=self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.canvas.pack() # pack canvas to window\n",
    "        \n",
    "        # make button to take pics\n",
    "        self.btn_snapshot = tk.Button(window, text=\"Take Photo\", width=20, command=self.snapshot) \n",
    "        self.btn_snapshot.pack(pady=10) # pack button to window\n",
    "\n",
    "        # Create a frame to contain the filter buttons\n",
    "        self.filter_frame = tk.Frame(window)\n",
    "        self.filter_frame.pack() # pack to window\n",
    "\n",
    "        # Pack filter buttons in a single row\n",
    "        filter_buttons = [\n",
    "            (\"Anonymous Filter\", self.apply_filter_anonymous),\n",
    "            (\"Clown Filter\", self.apply_filter_clown),\n",
    "            (\"Ayam Filter\", self.apply_filter_ayam),\n",
    "            (\"Luffy Filter\", self.apply_filter_luffy),\n",
    "            (\"Gojo Filter\", self.apply_filter_gojo)\n",
    "        ]\n",
    "\n",
    "        # make and pack filter button using for loop with corresponding commands\n",
    "        for text, command in filter_buttons:\n",
    "            btn = tk.Button(self.filter_frame, text=text, width=20, command=command)\n",
    "            btn.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "        \n",
    "        # make status label\n",
    "        self.status_label = tk.Label(window, text=\"\", font=(\"Arial\", 12))\n",
    "        self.status_label.pack(pady=5) # pack\n",
    "        \n",
    "        # initilialise flags for photo counter + application of filters\n",
    "        self.photo_counter = 0\n",
    "        self.apply_anonymous_flag = False\n",
    "        self.apply_clown_flag = False\n",
    "        self.apply_ayam_flag = False\n",
    "        self.apply_luffy_flag = False\n",
    "        self.apply_gojo_flag = False\n",
    "\n",
    "        #start update loop to continuously refresh video feed\n",
    "        self.update()\n",
    "        \n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.exit_app) # close window\n",
    "        self.window.mainloop() # start mainloop of window\n",
    "    \n",
    "    def snapshot(self): # this method takes pic from video feed\n",
    "        ret, frame = self.vid.read() # capture frame from video feed\n",
    "        if ret: # if sucessful\n",
    "            frame = self.apply_filters(frame) # apply the filter to the frame\n",
    "            self.photo_counter += 1 # increase photo counter whenever photo taken\n",
    "            filename = f\"snapshot_{self.photo_counter}.png\" # create file name (based on photo counter)\n",
    "            cv2.imwrite(filename, frame) # save captured frame as image using filename\n",
    "            self.update_status(f\"Snapshot {self.photo_counter} taken!\") # update status label\n",
    "    \n",
    "    def apply_filter_anonymous(self):\n",
    "        self.apply_anonymous_flag = not self.apply_anonymous_flag # flips the state true to false, vice versa\n",
    "        if self.apply_anonymous_flag: # if click on, turn off other filters\n",
    "            self.apply_ayam_flag = False\n",
    "            self.apply_clown_flag = False\n",
    "            self.apply_luffy_flag = False\n",
    "            self.apply_gojo_flag = False\n",
    "            self.update_status(\"Anonymous Filter applied.\") # update status\n",
    "        else: # if click off\n",
    "            self.update_status(\"Anonymous Filter turned off.\") # update status\n",
    "    \n",
    "    def apply_filter_clown(self):\n",
    "        self.apply_clown_flag = not self.apply_clown_flag\n",
    "        if self.apply_clown_flag:\n",
    "            self.apply_ayam_flag = False\n",
    "            self.apply_anonymous_flag = False\n",
    "            self.apply_luffy_flag = False\n",
    "            self.apply_gojo_flag = False\n",
    "            self.update_status(\"Clown Filter applied.\")\n",
    "        else:\n",
    "            self.update_status(\"Clown Filter turned off.\")\n",
    "\n",
    "    def apply_filter_ayam(self):\n",
    "        self.apply_ayam_flag = not self.apply_ayam_flag\n",
    "        if self.apply_ayam_flag:\n",
    "            self.apply_anonymous_flag = False\n",
    "            self.apply_clown_flag = False\n",
    "            self.apply_luffy_flag = False\n",
    "            self.apply_gojo_flag = False\n",
    "            self.update_status(\"Ayam Filter applied.\")\n",
    "        else:\n",
    "            self.update_status(\"Ayam Filter turned off.\")\n",
    "    \n",
    "    def apply_filter_luffy(self):\n",
    "        self.apply_luffy_flag = not self.apply_luffy_flag\n",
    "        if self.apply_luffy_flag:\n",
    "            self.apply_anonymous_flag = False\n",
    "            self.apply_clown_flag = False\n",
    "            self.apply_ayam_flag = False\n",
    "            self.apply_gojo_flag = False\n",
    "            self.update_status(\"Luffy Filter applied.\")\n",
    "        else:\n",
    "            self.update_status(\"Luffy Filter turned off.\")\n",
    "\n",
    "    def apply_filter_gojo(self):\n",
    "        self.apply_gojo_flag = not self.apply_gojo_flag\n",
    "        if self.apply_gojo_flag:\n",
    "            self.apply_anonymous_flag = False\n",
    "            self.apply_clown_flag = False\n",
    "            self.apply_ayam_flag = False\n",
    "            self.apply_luffy_flag = False\n",
    "            self.update_status(\"Gojo Filter applied.\")\n",
    "        else:\n",
    "            self.update_status(\"Gojo Filter turned off.\")\n",
    "\n",
    "    def apply_filters(self, frame): # apply filter to frame\n",
    "        if self.apply_anonymous_flag: # if active\n",
    "            frame = self.apply_anonymous_filter(frame) # apply\n",
    "        elif self.apply_clown_flag:\n",
    "            frame = self.apply_clown_filter(frame)\n",
    "        elif self.apply_ayam_flag:\n",
    "            frame = self.apply_ayam_filter(frame)\n",
    "        elif self.apply_luffy_flag:\n",
    "            frame = self.apply_luffy_filter(frame)\n",
    "        elif self.apply_gojo_flag:\n",
    "            frame = self.apply_gojo_filter(frame)\n",
    "        return frame\n",
    "    \n",
    "    def update(self): #updates video feed\n",
    "        ret, frame = self.vid.read() #read frame\n",
    "        if ret: #if sucessful\n",
    "            frame = self.apply_filters(frame) #apply filter to frame\n",
    "            #convert frame to image compatible w tk (BGR to RGB)\n",
    "            self.photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "            self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW) #display image\n",
    "            self.canvas.image = self.photo  # Keep a reference to the image to prevent garbage collection\n",
    "        self.window.after(10, self.update) #updates every 10 miliseconds\n",
    "    \n",
    "    def apply_anonymous_filter(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale for detection\n",
    "\n",
    "        #load face detection Haar Cascade\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        #detect the faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        #covers eye region with black rectangle\n",
    "        for (x, y, w, h) in faces:\n",
    "            eye_region_y = y + int(h * 1 / 4)\n",
    "            eye_region_h = int(h * 1 / 3)\n",
    "            cv2.rectangle(frame, (x, eye_region_y), (x + w, eye_region_y + eye_region_h), (0, 0, 0), -1)\n",
    "\n",
    "        #convert to grayscale then to color BGR format\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        return frame # return w anonymous filter applied\n",
    "\n",
    "    def apply_clown_filter(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # calc coordinates of nose in detected face rectangle\n",
    "            nose_x = x + w // 2 #width divide by 2 (top left)\n",
    "            nose_y = y + 3 * h // 5 #height div by 3 (top left)\n",
    "            cv2.circle(frame, (nose_x, nose_y), 30, (0, 0, 255), -1)  # red circle for nose\n",
    "\n",
    "            eye_y = y + h // 3 #height div by 3\n",
    "\n",
    "            # Blue triangles for eyes\n",
    "            cv2.drawContours(frame, [\n",
    "                np.array([\n",
    "                    (x + w // 4, eye_y), #left\n",
    "                    (x + w // 4 + 30, eye_y - 30), #top\n",
    "                    (x + w // 4 + 50, eye_y) #right\n",
    "                ])\n",
    "            ], 0, (255, 0, 0), -1)\n",
    "            cv2.drawContours(frame, [\n",
    "                np.array([\n",
    "                    (x + 3 * w // 4, eye_y), \n",
    "                    (x + 3 * w // 4 - 30, eye_y - 30), \n",
    "                    (x + 3 * w // 4 - 50, eye_y)\n",
    "                ])\n",
    "            ], 0, (255, 0, 0), -1)\n",
    "\n",
    "            eye_bottom_y = y + h // 2 - 10\n",
    "\n",
    "            # Inverted blue triangles for eye bottoms\n",
    "            cv2.drawContours(frame, [\n",
    "                np.array([\n",
    "                    (x + w // 4, eye_bottom_y), \n",
    "                    (x + w // 4 + 30, eye_bottom_y + 30), \n",
    "                    (x + w // 4 + 50, eye_bottom_y)\n",
    "                ])\n",
    "            ], 0, (255, 0, 0), -1)\n",
    "            cv2.drawContours(frame, [\n",
    "                np.array([\n",
    "                    (x + 3 * w // 4, eye_bottom_y), \n",
    "                    (x + 3 * w // 4 - 30, eye_bottom_y + 30), \n",
    "                    (x + 3 * w // 4 - 50, eye_bottom_y)\n",
    "                ])\n",
    "            ], 0, (255, 0, 0), -1)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def apply_ayam_filter(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        eye_img = cv2.imread('ayameye.PNG', -1)  # Load the eye image with alpha channel\n",
    "        nose_img = cv2.imread('ayamnose.PNG', -1)  # Load the nose image with alpha channel\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_roi = frame[y:y+h, x:x+w] # area of frame that encompasses the detected face\n",
    "\n",
    "            # Resize the eye image to match the size of the detected face region\n",
    "            eye_resized = cv2.resize(eye_img, (w, h))\n",
    "\n",
    "            # Create a mask using the alpha channel of the eye image\n",
    "            eye_mask = eye_resized[:, :, 3]  # Alpha channel of the eye image\n",
    "            eye_mask = cv2.cvtColor(eye_mask, cv2.COLOR_GRAY2BGR)  # Convert to 3-channel mask\n",
    "\n",
    "            # Use the mask to blend the eye image and the frame\n",
    "            eye_overlay = eye_resized[:, :, 0:3]  # Extract RGB channels\n",
    "            eye_background = cv2.bitwise_and(face_roi, 255 - eye_mask)  # Invert mask and extract region from the frame\n",
    "            face_roi[:] = cv2.add(eye_overlay, eye_background)  # Blend the image onto the frame\n",
    "\n",
    "            # Place the resized nose image over the nose area same cuz manual positioning\n",
    "            nose_resized = cv2.resize(nose_img, (w, h))\n",
    "\n",
    "            # Create a mask using the alpha channel of the nose image\n",
    "            nose_mask = nose_resized[:, :, 3]  # Alpha channel of the nose image\n",
    "            nose_mask = cv2.cvtColor(nose_mask, cv2.COLOR_GRAY2BGR)  # Convert to 3-channel mask\n",
    "\n",
    "            # Use the mask to blend the nose image and the frame\n",
    "            nose_overlay = nose_resized[:, :, 0:3]  # Extract RGB channels\n",
    "            nose_background = cv2.bitwise_and(face_roi, 255 - nose_mask)  # Invert mask and extract region from the frame\n",
    "            face_roi[:] = cv2.add(nose_overlay, nose_background)  # Blend the image onto the frame\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def apply_luffy_filter(self, frame):\n",
    "        # Load hat image with transparent background\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        hat_img = cv2.imread('luffyhat.PNG', -1)  # read hat image\n",
    "        hat_img = cv2.resize(hat_img, (300, 300))  # Adjust the size\n",
    "        scar_img = cv2.imread('luffyscar.PNG', -1)  # read scar image\n",
    "        scar_img = cv2.resize(scar_img, (50, 50))  # Adjust size as needed\n",
    "        \n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Adjust the hat position and size based on face detection\n",
    "            hat_width = int(2 * w)  # hat twice the face width\n",
    "            hat_height = int(1.25 * h) # hat 1.25 times the face height\n",
    "\n",
    "            # Resize the hat image based on the calculated width and height\n",
    "            resized_hat = cv2.resize(hat_img, (hat_width, hat_height))\n",
    "\n",
    "            # Calculate adjusted x-coordinate to ensure the hat remains within the frame\n",
    "            hat_x = max(0, x - int((hat_width - w) / 2))\n",
    "            \n",
    "            # Overlay the hat onto the frame\n",
    "            for i in range(hat_height):\n",
    "                for j in range(hat_width):\n",
    "                    if hat_x + j < frame.shape[1]:  # Ensure x-coordinate is within frame width\n",
    "                        if resized_hat[i, j][3] != 0:  # Check alpha channel for transparency\n",
    "                            frame[y + i - int(0.7 * h), hat_x + j] = resized_hat[i, j, 0:3]\n",
    "\n",
    "            # Add the scar under the right eye\n",
    "            scar_x = x + int(w * 0.6)  # x-coordinate for scar placement\n",
    "            scar_y = y + int(h * 0.4)  # y-coordinate for scar placement\n",
    "\n",
    "            # Overlay the scar onto the frame\n",
    "            for i in range(scar_img.shape[0]):\n",
    "                for j in range(scar_img.shape[1]):\n",
    "                    if scar_y + i < frame.shape[0] and scar_x + j < frame.shape[1]:\n",
    "                        if scar_img[i, j][3] != 0:  # Check alpha channel for transparency\n",
    "                            frame[scar_y + i, scar_x + j] = scar_img[i, j, 0:3]\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def apply_gojo_filter(self, frame):\n",
    "        gojo_img = cv2.imread('gojo.png', -1)  # Load the Gojo image with alpha channel\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        gojo_img = cv2.resize(gojo_img, (300, 300))  # Adjust size\n",
    "        \n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Adjust the gojo position and size based on face detection\n",
    "            gojo_width = int(2 * w)  #hat twice as wide\n",
    "            gojo_height = int(1.5 * h) # hat 1.5 times taller\n",
    "\n",
    "            # Resize the hat image based on the calculated width and height\n",
    "            resized_gojo = cv2.resize(gojo_img, (gojo_width, gojo_height))\n",
    "\n",
    "            # Calculate adjusted x-coordinate to ensure the hat remains within the frame\n",
    "            gojo_x = max(0, x - int((gojo_width - w) / 2))\n",
    "            \n",
    "            # Overlay gojo onto the frame\n",
    "            for i in range(gojo_height):\n",
    "                for j in range(gojo_width):\n",
    "                    if gojo_x + j < frame.shape[1]:  # Ensure x-coordinate is within frame width\n",
    "                        if resized_gojo[i, j][3] != 0:  # Check alpha channel for transparency\n",
    "                            frame[y + i - int(0.7 * h), gojo_x + j] = resized_gojo[i, j, 0:3]\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def exit_app(self): # for closing\n",
    "        self.vid.release()\n",
    "        self.window.destroy()\n",
    "    \n",
    "    def update_status(self, message): # update status labe;\n",
    "        self.status_label.config(text=message)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = CameraApp(root, \"Camera Filter App\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
